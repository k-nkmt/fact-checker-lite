{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49777ed9",
   "metadata": {},
   "source": [
    "# 検証用 Fact-Checker\n",
    "チームみらいが公開しているFact-CheckerからAI関連の処理のみを抽出して、動作を検証しやすいようにいpythonで実行できるようにしました。  \n",
    "Fact-Checkerをコマンドラインで動かすのと同様の動作で、入力されたテキストに対して判定を行います。  \n",
    "\n",
    "## 準備\n",
    "OpenAIのAPIキーに加えて、任意の参照したい資料をアップロードしたベクトルストアのIDを用意しておいてください。  \n",
    "ベクトルストアについては、APIプラットフォームにログインして、Dashboard > Storage からアップロードするのが手軽かと思います。  \n",
    "openaiのライブラリはあまり古すぎなければ実行可能かと思いますが、エラーとなるような場合はライブラリをアップデートしてください。  \n",
    "以下で動かした際のバージョンは1.82.0です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933bb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177deeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envを使用してAPIキーを読み込む場合\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# ベクトルストアのIDを指定\n",
    "vectorStoreId = \"your_vector_store_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check(statement: str) -> str:\n",
    "    \"\"\"\n",
    "    ファクトチェックを行う関数\n",
    "\n",
    "    :param statement: チェック対象の文\n",
    "    :return: ファクトチェックの結果\n",
    "    \"\"\"\n",
    "    if not statement:\n",
    "        return \"❌ 文章を引数で渡してください。例:\\n fact_check('地球は平らである')\"\n",
    "\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model= \"o3-mini\",\n",
    "        tools=[{\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [vectorStoreId],\n",
    "        }],\n",
    "        include=[\"file_search_call.results\"],\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "\t\t\t\"content\": \"\"\"あなたはファクトチェッカーです。  \n",
    "データソースと突き合わせて真偽を判定し、以下のフォーマットで答えてください。\n",
    "\n",
    "────────────────────────────────\n",
    "▼ステップ 0 : 事前フィルタ\n",
    "  ❶ 入力テキストが「客観的で検証可能な事実命題」か判定せよ。\n",
    "    ・感想／意見／価値判断のみ、あるいは一時的・主観的形容は対象外  \n",
    "    ・データソースに対応項目がまったく存在しない場合も対象外\n",
    "  ❷ 対象外なら OK とだけ出力し、理由を 1 行で補足（出典不要）。終了。\n",
    "\n",
    "▼ステップ 1 : 真偽判定（ステップ 0 を通過した場合のみ）\n",
    "  ❶ データソースで裏が取れるか確認し、次の三つから一つを選んで冒頭に出力  \n",
    "      OK  : データソースと完全に一致  \n",
    "      NG  : データソースと矛盾（誤りがある）  \n",
    "      OK : データソースに十分な情報がなく判定不能\n",
    "  ❷ その下に、判定根拠の短い説明  \n",
    "  ❸ どの箇所に載っているか（節・ページ等）を箇条書き  \n",
    "  ❹ 最後に出典（URL/文献名など）\n",
    "\n",
    "▼フォーマット例\n",
    "OK\n",
    "- 根拠: …\n",
    "- 該当箇所: …\n",
    "- 出典: …\n",
    "\n",
    "NG\n",
    "- 誤り: …\n",
    "- 正しい情報: …\n",
    "- 出典: …\n",
    "\n",
    "OK  ←ステップ 0 で終了\n",
    "入力文は主観的感想であり客観的事実ではないため。\n",
    "────────────────────────────────\n",
    "        \"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": statement,\n",
    "                },\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d86aaa",
   "metadata": {},
   "source": [
    "## 検証例\n",
    "\n",
    "おそらく検証用に使われたと思われる[ファイル](\n",
    "https://github.com/team-mirai/fact-checker/blob/15718cf7926685f0c5f15ad2fbf056009fb7a2a6/manifest.md)も公開されていたので、このファイルをベクトルストアにアップロードして、主な動作を確認してみます。\n",
    "Temperatureなどのパラメータの指定はされていないので、実行によって以下とは異なる回答・結果となる可能性はあります。\n",
    "\n",
    "４つ目の「データソースに十分な情報がなく判定不能なためOK」のケースは、参照するファイルが１ファイルのみなことや聞き方にも影響されると思いますが、参照するファイルに記述がないということでNGと判定されることが多いかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3aa1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK  \n",
      "- 理由: この文章は個人の主観的な感想であり、客観的かつ検証可能な事実命題ではないため。\n",
      "OK\n",
      "- 根拠: アップロードされた manifest.md ファイル内に「本マニフェストは作成途中版」と明記されており、マニフェストがまだ作業中で変更の可能性があることが記述されています 。\n",
      "- 該当箇所: manifest.md の冒頭部分および複数箇所（例: 、）で作成途中であることが明示されています。\n",
      "- 出典: manifest.md (アップロードされたファイル)\n",
      "NG\n",
      "- 誤り: チームみらいのマニュフェストは「完成」ではなく、公開されているドキュメントには「作成途中版」であり、議論中・作業中の箇所が多いと記されているため、５月末に完成したとの記述と矛盾します。\n",
      "- 正しい情報: マニフェストは皆さんの意見を取り入れながら改善される進行中のバージョンであり、完成版として発表されたものではありません。たとえば、manifest.md の内容には「作業中の箇所もたくさんある」との記述があります .\n",
      "- 出典: manifest.md ()\n",
      "NG\n",
      "- 誤り: 提供された文書内には、チームみらいがファクトチェック用のシステムをリリースしたという記述は見当たりません。\n",
      "- 正しい情報: マニフェストなどの文書は、政策や運営方針について論じられており、ファクトチェック用のシステムのリリースについては触れられていません  .\n",
      "- 出典: manifest.md (複数箇所)\n"
     ]
    }
   ],
   "source": [
    " # 主観的な感想なのでOK\n",
    "print(fact_check(\"今日は楽しかったです。\") )\n",
    "\n",
    " # データソースと一致しているのでOK\n",
    "print(fact_check(\"チームみらいのマニフェストは作成途中版らしい\") )\n",
    "\n",
    " # データソースと矛盾しているのでNG\n",
    "print(fact_check(\"チームみらいのマニュフェストは５月末でもう完成している\") )\n",
    "\n",
    " # データソースに十分な情報がなく(検証用に使用したファイルには未記載)、判定不能なためOK (結果ではMGと判定)\n",
    "print(fact_check(\"チームみらいはファクトチェック用のシステムをリリースしている\") )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
